# crawlers/keit.py
from __future__ import annotations
import re
from datetime import datetime
from typing import List, Dict, Any, Optional
import requests
from bs4 import BeautifulSoup

LIST_URL = "https://srome.keit.re.kr/srome/biz/perform/opnnPrpsl/retrieveTaskAnncmListView.do"

def _norm_date(s: Optional[str]) -> Optional[str]:
    if not s:
        return None
    s = s.strip().replace(".", "-").replace("/", "-")
    try:
        return datetime.strptime(s[:10], "%Y-%m-%d").strftime("%Y-%m-%d")
    except Exception:
        return s[:10] or None

def _parse_dt(s: Optional[str]) -> datetime:
    try:
        return datetime.strptime(s, "%Y-%m-%d")
    except Exception:
        return datetime.min

def _iris_link_from_ancm(ancm_id: str, year: str | None = None) -> str:
    """
    IRIS ìƒì„¸ëŠ” GETë¡œ ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥(ëŒ€ë¶€ë¶„).
    ì§„í–‰/ì¢…ë£Œ íƒ­ì— ë”°ë¼ ë³´ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ 'ancmIng' ê¸°ë³¸ ì œê³µ.
    í•„ìš”í•˜ë©´ ë©”íƒ€ì— 'ancmEnd'ë„ ê°™ì´ ë„£ì–´ë‘ì.
    """
    num = ancm_id[1:]
    return f"https://www.iris.go.kr/contents/retrieveBsnsAncmView.do?ancmId=0{num}&ancmPrg=ancmIng"

def fetch_keit_srome_notices(
    max_pages: int = 2,
    prgm_id: str = "XPG201040000",
    timeout: int = 15,
) -> List[Dict[str, Any]]:
    """
    KEIT SROME 'ê³¼ì œê³µê³ ' ëª©ë¡ íŒŒì‹± â†’ í†µì¼ ìŠ¤í‚¤ë§ˆë¡œ ë°˜í™˜
    """
    items: List[Dict[str, Any]] = []
    seen_ids: set[str] = set()  # ancmId ê¸°ì¤€ ì¤‘ë³µ ì œê±°

    sess = requests.Session()
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; KEITCrawler/1.0)",
        "Accept-Language": "ko",
    }

    # onclick ì˜ˆ: f_detail('I14917','2025') ë˜ëŠ” "f_detail('I14917', '2025'); return false;"
    onclick_re = re.compile(r"f_detail\(\s*'([^']+)'\s*,\s*'(\d{4})'\s*\)", re.I)

    for page in range(1, max_pages + 1):
        params = {"prgmId": prgm_id, "pageIndex": page}
        r = sess.get(LIST_URL, params=params, headers=headers, timeout=timeout)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        for box in soup.select(".table_list .table_box"):
            # ì œëª©
            title_tag = box.select_one(".table_box_detail .subject .title")
            if not title_tag:
                continue
            title = title_tag.get_text(strip=True)

            # ìƒì„¸ ë§í¬ (onclick íŒŒì‹±)
            a = box.select_one(".table_box_detail .subject a")
            onclick = (a.get("onclick") or "") if a else ""
            m = onclick_re.search(onclick)

            link = None
            iris_link = None
            reg_year = None
            ancm_id = None

            if m:
                ancm_id, reg_year = m.group(1), m.group(2)

                # SROME ìƒì„¸ (ì§ì ‘ í´ë¦­ìš©ìœ¼ë¡œëŠ” ë¹„ê¶Œì¥: POST/ì„¸ì…˜ ìš”êµ¬)
                srome_link = (
                    "https://srome.keit.re.kr/srome/biz/perform/opnnPrpsl/"
                    f"retrieveTaskAnncmView.do?ancmId={ancm_id}&bsnsYy={reg_year}&prgmId={prgm_id}"
                )

                iris_link = None
                if ancm_id.startswith("I") and ancm_id[1:].isdigit():
                    iris_link = _iris_link_from_ancm(ancm_id, reg_year)
                # (ì—¬ê¸°ê¹Œì§€: ë§í¬ ìƒì„±)

            # ë“±ë¡ì¼/ì ‘ìˆ˜ê¸°ê°„
            reg_date = None
            recv_period = None
            for ptag in box.select(".table_box_detail .info p"):
                label = ptag.select_one(".label")
                val = ptag.select_one(".value")
                if not label or not val:
                    continue
                lab = label.get_text(strip=True)
                v = val.get_text(strip=True)
                if "ë“±ë¡ì¼" in lab:
                    reg_date = _norm_date(v)
                elif "ì ‘ìˆ˜ê¸°ê°„" in lab:
                    recv_period = v.strip()

            items.append(
                {
                    "source": "KEIT",
                    "title": title,
                    # âœ… í´ë¦­ìš©ì€ IRISë¥¼ ìš°ì„ , ì—†ìœ¼ë©´ SROME
                    "link": iris_link or srome_link or "",
                    "date": reg_date,
                    "institution": "ì‚°ì—…í†µìƒìì›ë¶€ > í•œêµ­ì‚°ì—…ê¸°ìˆ í‰ê°€ì›",
                    "meta": {
                        "ê³µê³ ID": ancm_id or "",
                        "ê³µê³ ì—°ë„": reg_year or "",
                        "ê³µê³ ëª…": title,
                        "ê³µê³ ì¼ì": reg_date or "",
                        "ì ‘ìˆ˜ê¸°ê°„": recv_period or "",
                        "ì†Œê´€ë¶€ì²˜": "ì‚°ì—…í†µìƒìì›ë¶€",
                        "ì „ë¬¸ê¸°ê´€": "í•œêµ­ì‚°ì—…ê¸°ìˆ í‰ê°€ì›",
                        # ğŸ” ë°±ì—… ë§í¬ë„ ê°™ì´ ë³´ê´€(í”„ë¡ íŠ¸ì—ì„œ í•„ìš”ì‹œ ë…¸ì¶œ)
                        "backup_links": {
                            "srome": srome_link or "",
                            "iris_ing": iris_link or "",
                            "iris_end": (iris_link or "").replace("ancmIng", "ancmEnd") if iris_link else "",
                        },
                    },
                }
            )

    # ìµœì‹ ìˆœ ì •ë ¬ (ë“±ë¡ì¼ ì—†ìœ¼ë©´ ë’¤ë¡œ)
    items.sort(key=lambda it: _parse_dt(it.get("date")), reverse=True)
    return items


# ---------------------- ë©”ì¸ ì‹¤í–‰ë¶€ (ë‹¨ë… í…ŒìŠ¤íŠ¸ìš©) ----------------------
if __name__ == "__main__":
    import argparse, json

    parser = argparse.ArgumentParser(description="KEIT SROME ê³µê³  í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--pages", type=int, default=1, help="ê°€ì ¸ì˜¬ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ 1)")
    parser.add_argument("--prgm", type=str, default="XPG201040000", help="SROME prgmId")
    parser.add_argument("--limit", type=int, default=20, help="ì¶œë ¥ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸ 20)")
    parser.add_argument("--json", action="store_true", help="JSON í˜•íƒœë¡œ ì¶œë ¥")
    args = parser.parse_args()

    data = fetch_keit_srome_notices(max_pages=args.pages, prgm_id=args.prgm)
    if args.json:
        print(json.dumps(data[: args.limit], ensure_ascii=False, indent=2))
    else:
        print(f"[KEIT] ìˆ˜ì§‘ {len(data)}ê±´ (í‘œì‹œ {min(len(data), args.limit)}ê±´) â€” ìµœì‹ ìˆœ")
        for row in data[: args.limit]:
            print(f"{row.get('date','')} | {row.get('title','')} | {row.get('link','')}")
